{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.7-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36764bittensorflowconda7b2aaa6a1c344b04982f99c98a94bf0c",
   "display_name": "Python 3.6.7 64-bit ('tensorflow': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "* ### 快速搭建：(nn.Sequential自动forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Sequential(\n  (0): Linear(in_features=1, out_features=10, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=10, out_features=1, bias=True)\n)\n"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "net2 = nn.Sequential(\n",
    "    nn.Linear(1, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 1)\n",
    ")\n",
    "print(net2)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "* net2把激励函数也一同纳入进去了, 但是 net1 中, 激励函数实际上是在 forward() 功能中才被调用的. 这也就说明了, 相比 net2, net1 的好处就是, 你可以根据你的个人需要更加个性化你自己的前向传播过程, 比如(RNN). "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "* ### 保存 & 提取(save & restore)\n",
    "训练好了一个模型, 我们当然想要保存它, 留到下次要用的时候直接提取直接用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x1e0e5880730>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)    # random reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "state:{}\nparam_groups:[{'lr': 0.5, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [2065478105848, 2065478105704, 2065478106136, 2065478106280]}]\n"
    }
   ],
   "source": [
    "x = torch.unsqueeze(torch.linspace(-1, 1, 100), dim=1)  # x data (tensor), shape=(100, 1)\n",
    "y = x.pow(2) + 0.2*torch.rand(x.size())  # noisy y data (tensor), shape=(100, 1)\n",
    "\n",
    "net1 = nn.Sequential(\n",
    "    nn.Linear(1, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 1)\n",
    ")\n",
    "optimizer = torch.optim.SGD(net1.parameters(), lr=0.5)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "# 训练\n",
    "for t in range(100):\n",
    "    prediction = net1(x)\n",
    "    loss = loss_func(prediction, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \": \", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net1, 'net.pkl')  # 保存整个网络\n",
    "torch.save(net1.state_dict(), 'net_params.pkl')   # 只保存网络中的参数 (速度快, 占内存少)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取整个网络\n",
    "def restore_net():\n",
    "    # restore entire net1 to net2\n",
    "    net2 = torch.load('net.pkl')\n",
    "    prediction = net2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "restore_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0.weight:torch.Size([10, 1])\n0.bias:torch.Size([10])\n2.weight:torch.Size([1, 10])\n2.bias:torch.Size([1])\n"
    }
   ],
   "source": [
    "for param_tensor in net2.state_dict():\n",
    "    print(param_tensor, \": \", net2.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0.weight:torch.Size([10, 1])\n0.bias:torch.Size([10])\n2.weight:torch.Size([1, 10])\n2.bias:torch.Size([1])\n"
    }
   ],
   "source": [
    "net3 = nn.Sequential(\n",
    "        nn.Linear(1, 10),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(10, 1)\n",
    "    )\n",
    "\n",
    "for param_tensor in net3.state_dict():\n",
    "    print(param_tensor, \": \", net3.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "net3.load_state_dict(torch.load('net_params.pkl'))  # 只提取网络中参数\n",
    "prediction = net3(x)"
   ]
  }
 ]
}